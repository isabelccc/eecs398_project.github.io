{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Framing a Prediction Problem\n",
    "Predict the cause of a major power outage.\n",
    "\n",
    "In this project, we aim to predict the cause of a major power outage in the United States using relevant environmental, regional, and temporal data available at the time of the outage. The goal is to assist utility companies and policy-makers in proactively identifying risk factors and preparing mitigation strategies.\n",
    "\t•\tProblem Type: This is a multiclass classification task, as the target variable contains more than two distinct categories.\n",
    "\t•\tResponse Variable: CAUSE.CATEGORY — this column represents the high-level cause of the power outage (e.g., intentional attack, equipment failure, public appeal, etc.). We chose this variable because understanding the cause of an outage has practical value for prevention and planning.\n",
    "\t•\tEvaluation Metric: We use the macro-averaged F1-score to evaluate model performance. This metric is more appropriate than accuracy because our dataset is imbalanced, with some cause categories appearing much less frequently than others. Macro F1 equally weights each class, ensuring that rare but important categories are not ignored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Using cached geopandas-1.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shapely\n",
      "  Downloading shapely-2.1.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: folium in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (0.19.7)\n",
      "Requirement already satisfied: numpy>=1.24 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from geopandas) (1.26.0)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.11.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from geopandas) (2.1.0)\n",
      "Collecting pyproj>=3.5.0 (from geopandas)\n",
      "  Downloading pyproj-3.7.1-cp310-cp310-macosx_14_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: branca>=0.6.0 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from folium) (0.8.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from folium) (3.1.4)\n",
      "Requirement already satisfied: requests in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from folium) (2025.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from jinja2>=2.9->folium) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from pandas>=2.0.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from pandas>=2.0.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: certifi in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from pyogrio>=0.7.2->geopandas) (2024.7.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from requests->folium) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from requests->folium) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from requests->folium) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/linl/miniforge3/envs/pds/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.16.0)\n",
      "Using cached geopandas-1.1.0-py3-none-any.whl (338 kB)\n",
      "Downloading shapely-2.1.1-cp310-cp310-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading pyogrio-0.11.0-cp310-cp310-macosx_12_0_arm64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproj-3.7.1-cp310-cp310-macosx_14_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely, pyproj, pyogrio, geopandas\n",
      "Successfully installed geopandas-1.1.0 pyogrio-0.11.0 pyproj-3.7.1 shapely-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopandas shapely folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['variables', 'OBS', 'YEAR', 'MONTH', 'U.S._STATE', 'POSTAL.CODE',\n",
      "       'NERC.REGION', 'CLIMATE.REGION', 'ANOMALY.LEVEL', 'CLIMATE.CATEGORY',\n",
      "       'OUTAGE.START.DATE', 'OUTAGE.START.TIME', 'OUTAGE.RESTORATION.DATE',\n",
      "       'OUTAGE.RESTORATION.TIME', 'CAUSE.CATEGORY', 'CAUSE.CATEGORY.DETAIL',\n",
      "       'HURRICANE.NAMES', 'OUTAGE.DURATION', 'DEMAND.LOSS.MW',\n",
      "       'CUSTOMERS.AFFECTED', 'RES.PRICE', 'COM.PRICE', 'IND.PRICE',\n",
      "       'TOTAL.PRICE', 'RES.SALES', 'COM.SALES', 'IND.SALES', 'TOTAL.SALES',\n",
      "       'RES.PERCEN', 'COM.PERCEN', 'IND.PERCEN', 'RES.CUSTOMERS',\n",
      "       'COM.CUSTOMERS', 'IND.CUSTOMERS', 'TOTAL.CUSTOMERS', 'RES.CUST.PCT',\n",
      "       'COM.CUST.PCT', 'IND.CUST.PCT', 'PC.REALGSP.STATE', 'PC.REALGSP.USA',\n",
      "       'PC.REALGSP.REL', 'PC.REALGSP.CHANGE', 'UTIL.REALGSP', 'TOTAL.REALGSP',\n",
      "       'UTIL.CONTRI', 'PI.UTIL.OFUSA', 'POPULATION', 'POPPCT_URBAN',\n",
      "       'POPPCT_UC', 'POPDEN_URBAN', 'POPDEN_UC', 'POPDEN_RURAL',\n",
      "       'AREAPCT_URBAN', 'AREAPCT_UC', 'PCT_LAND', 'PCT_WATER_TOT',\n",
      "       'PCT_WATER_INLAND'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"outage.xlsx\", header=5)\n",
    "print(df.columns)\n",
    "df.head()\n",
    "\n",
    "df['U.S._STATE'].unique()\n",
    "df_valid = df[df[\"U.S._STATE\"].notna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question:\n",
    "What are the characteristics of major power outages with higher severity? Variables to consider include location, time, climate, land-use characteristics, electricity consumption patterns, economic characteristics, etc. What risk factors may an energy company want to look into when predicting the location and severity of its next major power outage?\n",
    "## Step 2: Data Cleaning and Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  U.S._STATE        OUTAGE.START  OUTAGE.RESTORATION  DURATION_HOURS\n",
      "1  Minnesota 2011-07-01 17:00:00 2011-07-03 20:00:00       51.000000\n",
      "2  Minnesota 2014-05-11 18:38:00 2014-05-11 18:39:00        0.016667\n",
      "3  Minnesota 2010-10-26 20:00:00 2010-10-28 22:00:00       50.000000\n",
      "4  Minnesota 2012-06-19 04:30:00 2012-06-20 23:00:00       42.500000\n",
      "5  Minnesota 2015-07-18 02:00:00 2015-07-19 07:00:00       29.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8b/h0bgsxld7w30r4lmjg26k6jc0000gn/T/ipykernel_61060/220339298.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_valid[\"OUTAGE.START\"] = pd.to_datetime(\n",
      "/var/folders/8b/h0bgsxld7w30r4lmjg26k6jc0000gn/T/ipykernel_61060/220339298.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid[\"OUTAGE.START\"] = pd.to_datetime(\n",
      "/var/folders/8b/h0bgsxld7w30r4lmjg26k6jc0000gn/T/ipykernel_61060/220339298.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_valid[\"OUTAGE.RESTORATION\"] = pd.to_datetime(\n",
      "/var/folders/8b/h0bgsxld7w30r4lmjg26k6jc0000gn/T/ipykernel_61060/220339298.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid[\"OUTAGE.RESTORATION\"] = pd.to_datetime(\n",
      "/var/folders/8b/h0bgsxld7w30r4lmjg26k6jc0000gn/T/ipykernel_61060/220339298.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid[\"DURATION_HOURS\"] = (df_valid[\"OUTAGE.RESTORATION\"] - df_valid[\"OUTAGE.START\"]).dt.total_seconds() / 3600\n",
      "/var/folders/8b/h0bgsxld7w30r4lmjg26k6jc0000gn/T/ipykernel_61060/220339298.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid.dropna(subset=[\"OUTAGE.START\", \"OUTAGE.RESTORATION\", \"DURATION_HOURS\"], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_valid[\"OUTAGE.START\"] = pd.to_datetime(\n",
    "    df_valid[\"OUTAGE.START.DATE\"].astype(str) + \" \" + df_valid[\"OUTAGE.START.TIME\"].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "df_valid[\"OUTAGE.RESTORATION\"] = pd.to_datetime(\n",
    "    df_valid[\"OUTAGE.RESTORATION.DATE\"].astype(str) + \" \" + df_valid[\"OUTAGE.RESTORATION.TIME\"].astype(str),\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "df_valid[\"DURATION_HOURS\"] = (df_valid[\"OUTAGE.RESTORATION\"] - df_valid[\"OUTAGE.START\"]).dt.total_seconds() / 3600\n",
    "df_valid.dropna(subset=[\"OUTAGE.START\", \"OUTAGE.RESTORATION\", \"DURATION_HOURS\"], inplace=True)\n",
    "\n",
    "\n",
    "print(df_valid[[\"U.S._STATE\", \"OUTAGE.START\", \"OUTAGE.RESTORATION\", \"DURATION_HOURS\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>OBS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>U.S._STATE</th>\n",
       "      <th>POSTAL.CODE</th>\n",
       "      <th>NERC.REGION</th>\n",
       "      <th>CLIMATE.REGION</th>\n",
       "      <th>ANOMALY.LEVEL</th>\n",
       "      <th>CLIMATE.CATEGORY</th>\n",
       "      <th>...</th>\n",
       "      <th>POPDEN_UC</th>\n",
       "      <th>POPDEN_RURAL</th>\n",
       "      <th>AREAPCT_URBAN</th>\n",
       "      <th>AREAPCT_UC</th>\n",
       "      <th>PCT_LAND</th>\n",
       "      <th>PCT_WATER_TOT</th>\n",
       "      <th>PCT_WATER_INLAND</th>\n",
       "      <th>OUTAGE.START</th>\n",
       "      <th>OUTAGE.RESTORATION</th>\n",
       "      <th>DURATION_HOURS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>normal</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.592666</td>\n",
       "      <td>8.407334</td>\n",
       "      <td>5.478743</td>\n",
       "      <td>2011-07-01 17:00:00</td>\n",
       "      <td>2011-07-03 20:00:00</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>normal</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.592666</td>\n",
       "      <td>8.407334</td>\n",
       "      <td>5.478743</td>\n",
       "      <td>2014-05-11 18:38:00</td>\n",
       "      <td>2014-05-11 18:39:00</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>cold</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.592666</td>\n",
       "      <td>8.407334</td>\n",
       "      <td>5.478743</td>\n",
       "      <td>2010-10-26 20:00:00</td>\n",
       "      <td>2010-10-28 22:00:00</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>normal</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.592666</td>\n",
       "      <td>8.407334</td>\n",
       "      <td>5.478743</td>\n",
       "      <td>2012-06-19 04:30:00</td>\n",
       "      <td>2012-06-20 23:00:00</td>\n",
       "      <td>42.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>1.2</td>\n",
       "      <td>warm</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.592666</td>\n",
       "      <td>8.407334</td>\n",
       "      <td>5.478743</td>\n",
       "      <td>2015-07-18 02:00:00</td>\n",
       "      <td>2015-07-19 07:00:00</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  variables  OBS    YEAR  MONTH U.S._STATE POSTAL.CODE NERC.REGION  \\\n",
       "1       NaN  1.0  2011.0    7.0  Minnesota          MN         MRO   \n",
       "2       NaN  2.0  2014.0    5.0  Minnesota          MN         MRO   \n",
       "3       NaN  3.0  2010.0   10.0  Minnesota          MN         MRO   \n",
       "4       NaN  4.0  2012.0    6.0  Minnesota          MN         MRO   \n",
       "5       NaN  5.0  2015.0    7.0  Minnesota          MN         MRO   \n",
       "\n",
       "       CLIMATE.REGION ANOMALY.LEVEL CLIMATE.CATEGORY  ... POPDEN_UC  \\\n",
       "1  East North Central          -0.3           normal  ...    1700.5   \n",
       "2  East North Central          -0.1           normal  ...    1700.5   \n",
       "3  East North Central          -1.5             cold  ...    1700.5   \n",
       "4  East North Central          -0.1           normal  ...    1700.5   \n",
       "5  East North Central           1.2             warm  ...    1700.5   \n",
       "\n",
       "  POPDEN_RURAL AREAPCT_URBAN AREAPCT_UC   PCT_LAND PCT_WATER_TOT  \\\n",
       "1         18.2          2.14        0.6  91.592666      8.407334   \n",
       "2         18.2          2.14        0.6  91.592666      8.407334   \n",
       "3         18.2          2.14        0.6  91.592666      8.407334   \n",
       "4         18.2          2.14        0.6  91.592666      8.407334   \n",
       "5         18.2          2.14        0.6  91.592666      8.407334   \n",
       "\n",
       "  PCT_WATER_INLAND        OUTAGE.START  OUTAGE.RESTORATION  DURATION_HOURS  \n",
       "1         5.478743 2011-07-01 17:00:00 2011-07-03 20:00:00       51.000000  \n",
       "2         5.478743 2014-05-11 18:38:00 2014-05-11 18:39:00        0.016667  \n",
       "3         5.478743 2010-10-26 20:00:00 2010-10-28 22:00:00       50.000000  \n",
       "4         5.478743 2012-06-19 04:30:00 2012-06-20 23:00:00       42.500000  \n",
       "5         5.478743 2015-07-18 02:00:00 2015-07-19 07:00:00       29.000000  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_columns = [\n",
    "    'YEAR', 'MONTH', 'U.S._STATE', 'CLIMATE.REGION', 'ANOMALY.LEVEL',\n",
    "    'CLIMATE.CATEGORY', 'CUSTOMERS.AFFECTED', 'POPDEN_URBAN', 'POPDEN_RURAL',\n",
    "    'AREAPCT_URBAN', 'AREAPCT_UC', 'PCT_LAND', 'PCT_WATER_TOT', 'PCT_WATER_INLAND',\n",
    "    'OUTAGE.START', 'OUTAGE.RESTORATION', 'DURATION_HOURS'\n",
    "]\n",
    "\n",
    "df_filtered = df[relevant_columns].copy()\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8b/h0bgsxld7w30r4lmjg26k6jc0000gn/T/ipykernel_61060/859558140.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid[\"LAT\"] = df_valid[\"U.S._STATE\"].map(lambda x: state_coords.get(x, [None, None])[0])\n",
      "/var/folders/8b/h0bgsxld7w30r4lmjg26k6jc0000gn/T/ipykernel_61060/859558140.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_valid[\"LON\"] = df_valid[\"U.S._STATE\"].map(lambda x: state_coords.get(x, [None, None])[1])\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "state_coords = {\n",
    "    'Alabama': [32.806671, -86.791130],\n",
    "    'Alaska': [61.370716, -152.404419],\n",
    "    'Arizona': [33.729759, -111.431221],\n",
    "    'Arkansas': [34.969704, -92.373123],\n",
    "    'California': [36.116203, -119.681564],\n",
    "    'Colorado': [39.059811, -105.311104],\n",
    "    'Connecticut': [41.597782, -72.755371],\n",
    "    'Delaware': [39.318523, -75.507141],\n",
    "    'District of Columbia': [38.897438, -77.026817],\n",
    "    'Florida': [27.766279, -81.686783],\n",
    "    'Georgia': [33.040619, -83.643074],\n",
    "    'Hawaii': [21.094318, -157.498337],\n",
    "    'Idaho': [44.240459, -114.478828],\n",
    "    'Illinois': [40.349457, -88.986137],\n",
    "    'Indiana': [39.849426, -86.258278],\n",
    "    'Iowa': [42.011539, -93.210526],\n",
    "    'Kansas': [38.526600, -96.726486],\n",
    "    'Kentucky': [37.668140, -84.670067],\n",
    "    'Louisiana': [31.169546, -91.867805],\n",
    "    'Maine': [44.693947, -69.381927],\n",
    "    'Maryland': [39.063946, -76.802101],\n",
    "    'Massachusetts': [42.230171, -71.530106],\n",
    "    'Michigan': [43.326618, -84.536095],\n",
    "    'Minnesota': [45.694454, -93.900192],\n",
    "    'Mississippi': [32.741646, -89.678696],\n",
    "    'Missouri': [38.456085, -92.288368],\n",
    "    'Montana': [46.921925, -110.454353],\n",
    "    'Nebraska': [41.125370, -98.268082],\n",
    "    'Nevada': [38.313515, -117.055374],\n",
    "    'New Hampshire': [43.452492, -71.563896],\n",
    "    'New Jersey': [40.298904, -74.521011],\n",
    "    'New Mexico': [34.840515, -106.248482],\n",
    "    'New York': [42.165726, -74.948051],\n",
    "    'North Carolina': [35.630066, -79.806419],\n",
    "    'North Dakota': [47.528912, -99.784012],\n",
    "    'Ohio': [40.388783, -82.764915],\n",
    "    'Oklahoma': [35.565342, -96.928917],\n",
    "    'Oregon': [44.572021, -122.070938],\n",
    "    'Pennsylvania': [40.590752, -77.209755],\n",
    "    'Rhode Island': [41.680893, -71.511780],\n",
    "    'South Carolina': [33.856892, -80.945007],\n",
    "    'South Dakota': [44.299782, -99.438828],\n",
    "    'Tennessee': [35.747845, -86.692345],\n",
    "    'Texas': [31.054487, -97.563461],\n",
    "    'Utah': [40.150032, -111.862434],\n",
    "    'Vermont': [44.045876, -72.710686],\n",
    "    'Virginia': [37.769337, -78.169968],\n",
    "    'Washington': [47.400902, -121.490494],\n",
    "    'West Virginia': [38.491226, -80.954570],\n",
    "    'Wisconsin': [44.268543, -89.616508],\n",
    "    'Wyoming': [42.755966, -107.302490]\n",
    "}\n",
    "\n",
    "df_valid[\"LAT\"] = df_valid[\"U.S._STATE\"].map(lambda x: state_coords.get(x, [None, None])[0])\n",
    "df_valid[\"LON\"] = df_valid[\"U.S._STATE\"].map(lambda x: state_coords.get(x, [None, None])[1])\n",
    "\n",
    "# 丢弃没有坐标的\n",
    "df_valid = df_valid.dropna(subset=[\"LAT\", \"LON\"])\n",
    "\n",
    "# 创建 GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df_valid, geometry=gpd.points_from_xy(df_valid[\"LON\"], df_valid[\"LAT\"]), crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration_by_cause.html\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "duration_by_cause = df_valid.groupby('CAUSE.CATEGORY')['DURATION_HOURS'].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "fig2 = px.bar(\n",
    "    duration_by_cause,\n",
    "    x='CAUSE.CATEGORY',\n",
    "    y='DURATION_HOURS',\n",
    "    title='Average Outage Duration by Cause',\n",
    "    labels={'CAUSE.CATEGORY': 'Cause of Outage', 'DURATION_HOURS': 'Average Duration (Hours)'},\n",
    "    color='CAUSE.CATEGORY'\n",
    ")\n",
    "fig2.update_layout(xaxis_title=\"Cause of Outage\", yaxis_title=\"Average Duration (Hours)\")\n",
    "\n",
    "# Save the graph to an HTML file\n",
    "fig2.write_html(\"duration_by_cause.html\")\n",
    "print(\"duration_by_cause.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to project/outages_over_time.html\n"
     ]
    }
   ],
   "source": [
    "# Create a 'YearMonth' column for aggregation\n",
    "df_valid['YearMonth'] = df_valid['OUTAGE.START'].dt.to_period('M').astype(str)\n",
    "outages_over_time = df_valid.groupby('YearMonth').size().reset_index(name='count')\n",
    "\n",
    "fig1 = px.line(\n",
    "    outages_over_time,\n",
    "    x='YearMonth',\n",
    "    y='count',\n",
    "    title='Number of Power Outages Over Time',\n",
    "    labels={'YearMonth': 'Month', 'count': 'Number of Outages'},\n",
    "    markers=True\n",
    ")\n",
    "fig1.update_layout(xaxis_title=\"Month\", yaxis_title=\"Number of Outages\")\n",
    "\n",
    "# Save the graph to an HTML file to embed in your website\n",
    "fig1.write_html(\"outages_over_time.html\")\n",
    "print(\"Saved to project/outages_over_time.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Graph 4: Outage Distribution by Climate Region...\n",
      "Saved to project/outages_by_region.html\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating Graph 4: Outage Distribution by Climate Region...\")\n",
    "outages_by_region = df_valid['CLIMATE.REGION'].value_counts().reset_index()\n",
    "outages_by_region.columns = ['CLIMATE.REGION', 'count']\n",
    "\n",
    "fig4 = px.treemap(\n",
    "    outages_by_region,\n",
    "    path=[px.Constant(\"All Regions\"), 'CLIMATE.REGION'],\n",
    "    values='count',\n",
    "    title='Proportion of Power Outages by Climate Region',\n",
    "    color_discrete_sequence=px.colors.qualitative.Pastel\n",
    ")\n",
    "fig4.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "\n",
    "# Save the graph to an HTML file\n",
    "fig4.write_html(\"outages_by_region.html\")\n",
    "print(\"Saved to project/outages_by_region.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Framing a Prediction Problem\n",
    "Predict the cause of a major power outage.\n",
    "\n",
    "In this project, we aim to predict the cause of a major power outage in the United States using relevant environmental, regional, and temporal data available at the time of the outage. The goal is to assist utility companies and policy-makers in proactively identifying risk factors and preparing mitigation strategies.\n",
    "\t•\tProblem Type: This is a multiclass classification task, as the target variable contains more than two distinct categories.\n",
    "\t•\tResponse Variable: CAUSE.CATEGORY — this column represents the high-level cause of the power outage (e.g., intentional attack, equipment failure, public appeal, etc.). We chose this variable because understanding the cause of an outage has practical value for prevention and planning.\n",
    "\t•\tEvaluation Metric: We use the macro-averaged F1-score to evaluate model performance. This metric is more appropriate than accuracy because our dataset is imbalanced, with some cause categories appearing much less frequently than others. Macro F1 equally weights each class, ensuring that rare but important categories are not ignored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import folium\n",
    "\n",
    "# 创建地图\n",
    "map = folium.Map(location=[37.8, -96], zoom_start=3)\n",
    "\n",
    "# 遍历数据，按州中心画圆点，大小与受影响人数成比例\n",
    "for _, row in df[df[\"U.S._STATE\"].notna() & df[\"CUSTOMERS.AFFECTED\"].notna()].iterrows():\n",
    "    state = row[\"U.S._STATE\"]\n",
    "    if state in state_coords:\n",
    "        affected = row[\"CUSTOMERS.AFFECTED\"]\n",
    "        \n",
    "        # 控制大小，使用对数放缩，防止极值过大\n",
    "        radius = min(30, max(4, affected**0.3 / 3)) \n",
    "        color = 'red' if affected > 500_000 else 'orange' if affected > 100_000 else 'green'\n",
    "        \n",
    "        folium.CircleMarker(\n",
    "            location=state_coords[state],\n",
    "            radius=radius,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_opacity=0.7,\n",
    "            popup=f\"{state}<br>Cause: {row['CAUSE.CATEGORY']}<br>Affected: {int(affected):,}\"\n",
    "        ).add_to(map)\n",
    "\n",
    "# 保存 HTML\n",
    "with open(\"outages_map.html\", \"w\") as f:\n",
    "    f.write(map._repr_html_())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Framing a Prediction Problem\n",
    "Predict the cause of a major power outage.\n",
    "\n",
    "In this project, we aim to predict the cause of a major power outage in the United States using relevant environmental, regional, and temporal data available at the time of the outage. The goal is to assist utility companies and policy-makers in proactively identifying risk factors and preparing mitigation strategies.\n",
    "\t•\tProblem Type: This is a multiclass classification task, as the target variable contains more than two distinct categories.\n",
    "\t•\tResponse Variable: CAUSE.CATEGORY — this column represents the high-level cause of the power outage (e.g., intentional attack, equipment failure, public appeal, etc.). We chose this variable because understanding the cause of an outage has practical value for prevention and planning.\n",
    "\t•\tEvaluation Metric: We use the macro-averaged F1-score to evaluate model performance. This metric is more appropriate than accuracy because our dataset is imbalanced, with some cause categories appearing much less frequently than others. Macro F1 equally weights each class, ensuring that rare but important categories are not ignored.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
